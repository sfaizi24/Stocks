{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Rate-Limited FULL MARKET Data Collection (Year by Year)\n\n",
    "This notebook collects financial data for **ALL US tickers** (~12,000) with strict rate limiting and saves each year separately.\n\n",
    "**Key features:**\n",
    "1. **Rate limiting**: 750 API calls per minute (75 tickers/minute max)\n",
    "2. **Full market coverage**: ~12,000 US tickers (NYSE/NASDAQ)\n",
    "3. **Year-by-year collection**: Each year saved to separate CSV\n",
    "4. **Error tracking**: Detailed logs for debugging\n",
    "5. **Manual control**: Run each year when you want\n",
    "6. **Progress saving**: Can resume if interrupted\n\n",
    "**Target columns:** `quarter`, `ticker`, `industry`, `sector`, `debt_to_assets`, `mkt_cap`, `stock_price`, `mkt_cap_rank`\n\n",
    "**Total time estimate:** ~16 hours for all 6 years (2.7 hours per year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# \u26a0\ufe0f FULL MARKET COLLECTION WARNING\n\n**This notebook is configured to collect data for ALL US tickers (~12,000 companies).**\n\n**Time requirements:**\n- **Per year:** ~2.7 hours (with 300 API calls/minute rate limiting)\n- **All 6 years (2019-2024):** ~16 hours total\n- **API calls:** ~288,000 total (48,000 per year)\n\n**To start with a smaller test:**\n1. Change `MAX_TICKERS = None` to `MAX_TICKERS = 100` in any collection cell\n2. Run one year first to verify everything works\n3. Then change back to `MAX_TICKERS = None` for full collection\n\n**Pro tip:** Run each year separately and let them complete overnight or during long breaks.\n\n---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import Optional, List, Dict, Any, Tuple\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Your API key\n",
    "API = \"7cNMpVzb43GKtm05iRTDWJtyJXSylX8J\"\n",
    "\n",
    "# Rate limiting configuration\n",
    "API_CALLS_PER_MINUTE = 750\n",
    "API_CALLS_PER_TICKER = 4  # balance sheet, market cap, price, profile\n",
    "TICKERS_PER_MINUTE = API_CALLS_PER_MINUTE // API_CALLS_PER_TICKER  # 75 tickers/minute\n",
    "SECONDS_PER_TICKER = 60 / TICKERS_PER_MINUTE  # 0.8 seconds per ticker\n",
    "\n",
    "print(f\"Rate limit configured: {TICKERS_PER_MINUTE} tickers/minute ({SECONDS_PER_TICKER:.2f} seconds/ticker)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper Functions with Rate Limiting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_json(url: str, params: Dict[str, Any] = {}) -> Optional[List[Dict]]:\n",
    "    \"\"\"Safely get JSON data from API with error handling and rate limit retry\"\"\"\n",
    "    try:\n",
    "        params[\"apikey\"] = API\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        \n",
    "        # Handle rate limiting\n",
    "        if response.status_code == 429:\n",
    "            print(f\"\u26a0\ufe0f  Rate limit hit! Waiting 30 seconds...\")\n",
    "            time.sleep(30)\n",
    "            return get_json(url, params)  # Retry\n",
    "            \n",
    "        response.raise_for_status()\n",
    "        js = response.json()\n",
    "        \n",
    "        # Handle different response formats\n",
    "        if isinstance(js, dict) and \"historical\" in js:\n",
    "            return js[\"historical\"]\n",
    "        elif isinstance(js, list):\n",
    "            return js\n",
    "        else:\n",
    "            print(f\"Unexpected response format: {type(js)}\")\n",
    "            return None\n",
    "            \n",
    "    except requests.exceptions.HTTPError as e:\n",
    "        print(f\"HTTP Error {e.response.status_code}: {e}\")\n",
    "        return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_ticker_year(ticker: str, year: int) -> Tuple[Optional[pd.DataFrame], Dict[str, Any]]:\n",
    "    \"\"\"Process data for a single ticker for a specific year\"\"\"\n",
    "    error_log = {\"ticker\": ticker, \"year\": year, \"errors\": []}\n",
    "    \n",
    "    try:\n",
    "        # Calculate date range for the specific year\n",
    "        start_date = datetime(year, 1, 1)\n",
    "        end_date = datetime(year, 12, 31)\n",
    "        \n",
    "        # Get balance sheet data (API call 1)\n",
    "        bs = get_json(\n",
    "            f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}\", \n",
    "            {\"period\": \"quarter\", \"limit\": 20}  # Get enough quarters\n",
    "        )\n",
    "        \n",
    "        # Get market cap data (API call 2)\n",
    "        mc = get_json(\n",
    "            f\"https://financialmodelingprep.com/api/v3/historical-market-capitalization/{ticker}\", \n",
    "            {\"from\": start_date.strftime(\"%Y-%m-%d\"), \"to\": end_date.strftime(\"%Y-%m-%d\")}\n",
    "        )\n",
    "        \n",
    "        # Get price data (API call 3)\n",
    "        px = get_json(\n",
    "            f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}\", \n",
    "            {\"from\": start_date.strftime(\"%Y-%m-%d\"), \"to\": end_date.strftime(\"%Y-%m-%d\")}\n",
    "        )\n",
    "        \n",
    "        # Get company profile (API call 4)\n",
    "        profile = get_json(f\"https://financialmodelingprep.com/api/v3/profile/{ticker}\")\n",
    "        \n",
    "        # Track missing data\n",
    "        if not bs:\n",
    "            error_log[\"errors\"].append(\"No balance sheet data\")\n",
    "        if not mc:\n",
    "            error_log[\"errors\"].append(\"No market cap data\")\n",
    "        if not px:\n",
    "            error_log[\"errors\"].append(\"No price data\")\n",
    "        if not profile:\n",
    "            error_log[\"errors\"].append(\"No profile data\")\n",
    "            \n",
    "        if not all([bs, mc, px, profile]):\n",
    "            return None, error_log\n",
    "        \n",
    "        # Extract company info\n",
    "        industry = profile[0].get(\"industry\", \"Unknown\")\n",
    "        sector = profile[0].get(\"sector\", \"Unknown\")\n",
    "        \n",
    "        # Process balance sheet data\n",
    "        bs_df = pd.DataFrame(bs)\n",
    "        bs_df['date'] = pd.to_datetime(bs_df['date'])\n",
    "        # Filter for specific year\n",
    "        bs_df = bs_df[bs_df['date'].dt.year == year]\n",
    "        \n",
    "        if len(bs_df) == 0:\n",
    "            error_log[\"errors\"].append(f\"No balance sheet data for year {year}\")\n",
    "            return None, error_log\n",
    "            \n",
    "        bs_df = (\n",
    "            bs_df[['date', 'shortTermDebt', 'longTermDebt', 'totalAssets']]\n",
    "            .assign(\n",
    "                quarter=lambda d: d.date.dt.to_period(\"Q\"),\n",
    "                debt_to_assets=lambda d: (\n",
    "                    (d.shortTermDebt.fillna(0) + d.longTermDebt.fillna(0)) / \n",
    "                    d.totalAssets.replace(0, pd.NA)\n",
    "                )\n",
    "            )\n",
    "            .dropna(subset=[\"debt_to_assets\"])\n",
    "        )\n",
    "        \n",
    "        # Process market cap data\n",
    "        mc_df = (\n",
    "            pd.DataFrame(mc)\n",
    "            .assign(\n",
    "                date=lambda d: pd.to_datetime(d.date),\n",
    "                quarter=lambda d: d.date.dt.to_period(\"Q\")\n",
    "            )\n",
    "            .sort_values(\"date\")\n",
    "            .drop_duplicates(\"quarter\", keep=\"last\")\n",
    "            .rename(columns={\"marketCap\": \"mkt_cap\"})\n",
    "            [['quarter', 'mkt_cap']]\n",
    "        )\n",
    "        \n",
    "        # Process price data (using adjusted close)\n",
    "        px_df = (\n",
    "            pd.DataFrame(px)\n",
    "            .assign(\n",
    "                date=lambda d: pd.to_datetime(d.date),\n",
    "                quarter=lambda d: d.date.dt.to_period(\"Q\")\n",
    "            )\n",
    "            .sort_values(\"date\")\n",
    "            .drop_duplicates(\"quarter\", keep=\"last\")\n",
    "            .rename(columns={\"adjClose\": \"stock_price\"})\n",
    "            [['quarter', 'stock_price']]\n",
    "        )\n",
    "        \n",
    "        # Merge all data\n",
    "        merged = (\n",
    "            bs_df.merge(mc_df, on=\"quarter\", how=\"left\")\n",
    "                 .merge(px_df, on=\"quarter\", how=\"left\")\n",
    "                 .assign(ticker=ticker, industry=industry, sector=sector)\n",
    "                 [['quarter', 'ticker', 'industry', 'sector', 'debt_to_assets', 'mkt_cap', 'stock_price']]\n",
    "                 .dropna()\n",
    "        )\n",
    "        \n",
    "        if len(merged) == 0:\n",
    "            error_log[\"errors\"].append(\"No valid data after merging\")\n",
    "            return None, error_log\n",
    "            \n",
    "        return merged, error_log\n",
    "        \n",
    "    except Exception as e:\n",
    "        error_log[\"errors\"].append(f\"Exception: {str(e)}\")\n",
    "        return None, error_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collect_year_data(tickers: List[str], year: int, max_tickers: Optional[int] = None, \n",
    "                     save_progress: bool = True, progress_interval: int = 100) -> Tuple[pd.DataFrame, List[Dict]]:\n",
    "    \"\"\"Collect data for multiple tickers for a specific year with strict rate limiting\"\"\"\n",
    "    all_data = []\n",
    "    all_errors = []\n",
    "    successful_tickers = []\n",
    "    failed_tickers = []\n",
    "    \n",
    "    tickers_to_process = tickers[:max_tickers] if max_tickers else tickers\n",
    "    total_tickers = len(tickers_to_process)\n",
    "    \n",
    "    print(f\"\\n{'='*70}\")\n",
    "    print(f\"  COLLECTING DATA FOR YEAR {year}\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total tickers: {total_tickers}\")\n",
    "    print(f\"Estimated time: {(total_tickers * SECONDS_PER_TICKER / 60):.1f} minutes\")\n",
    "    print(f\"API calls: {total_tickers * API_CALLS_PER_TICKER} (at {API_CALLS_PER_MINUTE}/minute)\")\n",
    "    print(f\"Progress saves: Every {progress_interval} tickers\")\n",
    "    print(f\"{'='*70}\\n\")\n",
    "    \n",
    "    start_time = time.time()\n",
    "    \n",
    "    for i, ticker in enumerate(tickers_to_process):\n",
    "        ticker_start = time.time()\n",
    "        \n",
    "        # Progress update\n",
    "        if i > 0 and i % 20 == 0:\n",
    "            elapsed = time.time() - start_time\n",
    "            avg_time = elapsed / i\n",
    "            remaining = (total_tickers - i) * avg_time\n",
    "            success_rate = len(successful_tickers) / i * 100\n",
    "            \n",
    "            print(f\"\\n[Progress: {i}/{total_tickers} ({i/total_tickers*100:.1f}%)]\")\n",
    "            print(f\"  Time: {elapsed/60:.1f}min elapsed, ~{remaining/60:.1f}min remaining\")\n",
    "            print(f\"  Success rate: {success_rate:.1f}% ({len(successful_tickers)}/{i})\")\n",
    "            print(f\"  Current batch: \", end=\"\")\n",
    "        \n",
    "        # Process ticker\n",
    "        ticker_data, error_log = process_ticker_year(ticker, year)\n",
    "        \n",
    "        if ticker_data is not None and len(ticker_data) > 0:\n",
    "            all_data.append(ticker_data)\n",
    "            successful_tickers.append(ticker)\n",
    "            print(f\"\u2713\", end=\"\")\n",
    "        else:\n",
    "            failed_tickers.append(ticker)\n",
    "            all_errors.append(error_log)\n",
    "            print(f\"\u2717\", end=\"\")\n",
    "        \n",
    "        # Save progress periodically\n",
    "        if save_progress and (i + 1) % progress_interval == 0 and all_data:\n",
    "            temp_df = pd.concat(all_data, ignore_index=True)\n",
    "            temp_df['mkt_cap_rank'] = temp_df.groupby('quarter')['mkt_cap'].rank(method='dense', ascending=False).astype(int)\n",
    "            progress_filename = f\"progress_{year}_tickers_{i+1}.csv\"\n",
    "            temp_df.to_csv(progress_filename, index=False)\n",
    "            print(f\"\\n  \ud83d\udcbe Progress saved: {progress_filename} ({len(temp_df)} rows)\")\n",
    "        \n",
    "        # Strict rate limiting\n",
    "        ticker_elapsed = time.time() - ticker_start\n",
    "        if ticker_elapsed < SECONDS_PER_TICKER:\n",
    "            time.sleep(SECONDS_PER_TICKER - ticker_elapsed)\n",
    "    \n",
    "    # Final summary\n",
    "    total_time = time.time() - start_time\n",
    "    \n",
    "    print(f\"\\n\\n{'='*70}\")\n",
    "    print(f\"  YEAR {year} COLLECTION COMPLETE\")\n",
    "    print(f\"{'='*70}\")\n",
    "    print(f\"Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
    "    print(f\"Successful: {len(successful_tickers)} tickers ({len(successful_tickers)/total_tickers*100:.1f}%)\")\n",
    "    print(f\"Failed: {len(failed_tickers)} tickers\")\n",
    "    print(f\"Actual rate: {total_tickers/total_time*60:.1f} tickers/minute\")\n",
    "    \n",
    "    if len(all_data) == 0:\n",
    "        print(\"\\n\u26a0\ufe0f  No data collected!\")\n",
    "        return pd.DataFrame(columns=[\"quarter\", \"ticker\", \"industry\", \"sector\", \n",
    "                                    \"debt_to_assets\", \"mkt_cap\", \"stock_price\", \"mkt_cap_rank\"]), all_errors\n",
    "    \n",
    "    # Combine all data\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df = final_df.sort_values(['ticker', 'quarter']).reset_index(drop=True)\n",
    "    \n",
    "    # Add market cap ranking\n",
    "    final_df['mkt_cap_rank'] = final_df.groupby('quarter')['mkt_cap'].rank(method='dense', ascending=False).astype(int)\n",
    "    \n",
    "    print(f\"\\n\ud83d\udcca Final dataset: {len(final_df)} rows, {final_df['ticker'].nunique()} tickers\")\n",
    "    print(f\"   Quarters: {sorted(final_df['quarter'].unique())}\")\n",
    "    \n",
    "    # Save error log\n",
    "    if all_errors:\n",
    "        error_filename = f\"errors_{year}.json\"\n",
    "        with open(error_filename, 'w') as f:\n",
    "            json.dump(all_errors, f, indent=2, default=str)\n",
    "        print(f\"\\n\ud83d\udcdd Error log saved: {error_filename} ({len(all_errors)} errors)\")\n",
    "    \n",
    "    # Clean up progress files\n",
    "    if save_progress:\n",
    "        for progress_file in [f for f in os.listdir('.') if f.startswith(f'progress_{year}_')]:\n",
    "            os.remove(progress_file)\n",
    "        print(f\"\ud83e\uddf9 Cleaned up progress files\")\n",
    "    \n",
    "    return final_df, all_errors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Get List of US Tickers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get list of US tickers\n",
    "print(\"Fetching ticker list...\")\n",
    "tickers_data = get_json(\"https://financialmodelingprep.com/api/v3/stock/list\")\n",
    "\n",
    "if tickers_data:\n",
    "    # Filter for US exchanges and remove penny stocks\n",
    "    us_tickers = [\n",
    "        d[\"symbol\"] for d in tickers_data \n",
    "        if d[\"exchangeShortName\"] in [\"NYSE\", \"NASDAQ\"] \n",
    "        and (d.get(\"price\") is not None and d.get(\"price\", 0) > 5)\n",
    "        and len(d[\"symbol\"]) <= 5\n",
    "        and \".\" not in d[\"symbol\"]\n",
    "    ]\n",
    "    \n",
    "    print(f\"\u2705 Found {len(us_tickers)} US tickers\")\n",
    "    print(f\"   Sample: {us_tickers[:10]}\")\n",
    "else:\n",
    "    print(\"\u274c Failed to fetch ticker list. Using sample tickers.\")\n",
    "    us_tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"JPM\", \"JNJ\", \"V\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Test with Single Ticker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test with AAPL for 2023\n",
    "print(\"Testing with AAPL for year 2023...\")\n",
    "test_start = time.time()\n",
    "\n",
    "test_data, test_errors = process_ticker_year(\"AAPL\", 2023)\n",
    "\n",
    "test_time = time.time() - test_start\n",
    "print(f\"\\nTest completed in {test_time:.2f} seconds\")\n",
    "\n",
    "if test_data is not None:\n",
    "    print(\"\\n\u2705 Test successful!\")\n",
    "    print(test_data)\n",
    "    print(f\"\\nQuarters found: {sorted(test_data['quarter'].unique())}\")\n",
    "else:\n",
    "    print(\"\\n\u274c Test failed!\")\n",
    "    print(\"Errors:\", test_errors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#",
    "#",
    " ",
    "S",
    "t",
    "e",
    "p",
    " ",
    "3",
    ":",
    " ",
    "C",
    "o",
    "l",
    "l",
    "e",
    "c",
    "t",
    " ",
    "D",
    "a",
    "t",
    "a",
    " ",
    "f",
    "o",
    "r",
    " ",
    "2",
    "0",
    "2",
    "4",
    "\n",
    "\n",
    "C",
    "o",
    "l",
    "l",
    "e",
    "c",
    "t",
    " ",
    "d",
    "a",
    "t",
    "a",
    " ",
    "f",
    "o",
    "r",
    " ",
    "A",
    "L",
    "L",
    " ",
    "U",
    "S",
    " ",
    "t",
    "i",
    "c",
    "k",
    "e",
    "r",
    "s",
    " ",
    "f",
    "o",
    "r",
    " ",
    "2",
    "0",
    "2",
    "4",
    ".",
    " ",
    "T",
    "h",
    "i",
    "s",
    " ",
    "w",
    "i",
    "l",
    "l",
    " ",
    "t",
    "a",
    "k",
    "e",
    " ",
    "a",
    "p",
    "p",
    "r",
    "o",
    "x",
    "i",
    "m",
    "a",
    "t",
    "e",
    "l",
    "y",
    " ",
    "*",
    "*",
    "2",
    ".",
    "7",
    " ",
    "h",
    "o",
    "u",
    "r",
    "s",
    "*",
    "*",
    " ",
    "w",
    "i",
    "t",
    "h",
    " ",
    "r",
    "a",
    "t",
    "e",
    " ",
    "l",
    "i",
    "m",
    "i",
    "t",
    "i",
    "n",
    "g",
    ".",
    "\n",
    "\n",
    "*",
    "*",
    "N",
    "o",
    "t",
    "e",
    ":",
    "*",
    "*",
    " ",
    "S",
    "i",
    "n",
    "c",
    "e",
    " ",
    "2",
    "0",
    "2",
    "4",
    " ",
    "i",
    "s",
    " ",
    "o",
    "n",
    "g",
    "o",
    "i",
    "n",
    "g",
    ",",
    " ",
    "y",
    "o",
    "u",
    " ",
    "m",
    "a",
    "y",
    " ",
    "h",
    "a",
    "v",
    "e",
    " ",
    "p",
    "a",
    "r",
    "t",
    "i",
    "a",
    "l",
    " ",
    "d",
    "a",
    "t",
    "a",
    " ",
    "(",
    "Q",
    "1",
    "-",
    "Q",
    "3",
    " ",
    "o",
    "r",
    " ",
    "Q",
    "1",
    "-",
    "Q",
    "4",
    " ",
    "d",
    "e",
    "p",
    "e",
    "n",
    "d",
    "i",
    "n",
    "g",
    " ",
    "o",
    "n",
    " ",
    "c",
    "u",
    "r",
    "r",
    "e",
    "n",
    "t",
    " ",
    "d",
    "a",
    "t",
    "e",
    ")",
    ".",
    "\n",
    "\n",
    "*",
    "*",
    "T",
    "i",
    "m",
    "e",
    " ",
    "e",
    "s",
    "t",
    "i",
    "m",
    "a",
    "t",
    "e",
    ":",
    "*",
    "*",
    " ",
    "~",
    "1",
    "2",
    ",",
    "0",
    "0",
    "0",
    " ",
    "t",
    "i",
    "c",
    "k",
    "e",
    "r",
    "s",
    " ",
    "\u00d7",
    " ",
    "0",
    ".",
    "8",
    " ",
    "s",
    "e",
    "c",
    "o",
    "n",
    "d",
    "s",
    " ",
    "=",
    " ",
    "2",
    ".",
    "7",
    " ",
    "h",
    "o",
    "u",
    "r",
    "s",
    "\n",
    "\n",
    "T",
    "o",
    " ",
    "t",
    "e",
    "s",
    "t",
    " ",
    "w",
    "i",
    "t",
    "h",
    " ",
    "f",
    "e",
    "w",
    "e",
    "r",
    " ",
    "t",
    "i",
    "c",
    "k",
    "e",
    "r",
    "s",
    " ",
    "f",
    "i",
    "r",
    "s",
    "t",
    ",",
    " ",
    "c",
    "h",
    "a",
    "n",
    "g",
    "e",
    " ",
    "`",
    "M",
    "A",
    "X",
    "_",
    "T",
    "I",
    "C",
    "K",
    "E",
    "R",
    "S",
    " ",
    "=",
    " ",
    "N",
    "o",
    "n",
    "e",
    "`",
    " ",
    "t",
    "o",
    " ",
    "`",
    "M",
    "A",
    "X",
    "_",
    "T",
    "I",
    "C",
    "K",
    "E",
    "R",
    "S",
    " ",
    "=",
    " ",
    "1",
    "0",
    "0",
    "`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 2024 data\n",
    "YEAR = 2024\n",
    "MAX_TICKERS = None  # Collect ALL US tickers (~12,000)\n",
    "data_2024, errors_2024 = collect_year_data(us_tickers, year=YEAR, max_tickers=MAX_TICKERS)\n\n",
    "if len(data_2024) > 0:\n",
    "    filename = f\"stock_data_{YEAR}.csv\"\n",
    "    data_2024.to_csv(filename, index=False)\n",
    "    print(f\"\\n\u2705 Data saved to '{filename}'\")\n",
    "    \n",
    "    # Show top companies (use latest quarter available)\n",
    "    latest_quarter = data_2024['quarter'].max()\n",
    "    latest_data = data_2024[data_2024['quarter'] == latest_quarter]\n",
    "    if len(latest_data) > 0:\n",
    "        print(f\"\\n\ud83c\udfc6 Top 10 companies by market cap ({latest_quarter}):\")\n",
    "        top_10 = latest_data.nsmallest(10, 'mkt_cap_rank')[['ticker', 'mkt_cap_rank', 'mkt_cap', 'industry']]\n",
    "        print(top_10.to_string(index=False))\n",
    "    \n",
    "    # Show available quarters\n",
    "    print(f\"\\n\ud83d\udcc5 Available quarters for 2024: {sorted(data_2024['quarter'].unique())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#",
    "#",
    " ",
    "S",
    "t",
    "e",
    "p",
    " ",
    "4",
    ":",
    " ",
    "C",
    "o",
    "l",
    "l",
    "e",
    "c",
    "t",
    " ",
    "D",
    "a",
    "t",
    "a",
    " ",
    "f",
    "o",
    "r",
    " ",
    "2",
    "0",
    "2",
    "3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 2023 data\n",
    "YEAR = 2023\n",
    "MAX_TICKERS = None  # Collect ALL US tickers (~12,000)\n",
    "\n",
    "data_2023, errors_2023 = collect_year_data(us_tickers, year=YEAR, max_tickers=MAX_TICKERS)\n",
    "\n",
    "if len(data_2023) > 0:\n",
    "    filename = f\"stock_data_{YEAR}.csv\"\n",
    "    data_2023.to_csv(filename, index=False)\n",
    "    print(f\"\\n\u2705 Data saved to '{filename}'\")\n",
    "    \n",
    "    # Show top companies\n",
    "    q4_data = data_2023[data_2023['quarter'] == f'{YEAR}Q4']\n",
    "    if len(q4_data) > 0:\n",
    "        print(f\"\\n\ud83c\udfc6 Top 10 companies by market cap (Q4 {YEAR}):\")\n",
    "        top_10 = q4_data.nsmallest(10, 'mkt_cap_rank')[['ticker', 'mkt_cap_rank', 'mkt_cap', 'industry']]\n",
    "        print(top_10.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#",
    "#",
    " ",
    "S",
    "t",
    "e",
    "p",
    " ",
    "5",
    ":",
    " ",
    "C",
    "o",
    "l",
    "l",
    "e",
    "c",
    "t",
    " ",
    "D",
    "a",
    "t",
    "a",
    " ",
    "f",
    "o",
    "r",
    " ",
    "2",
    "0",
    "2",
    "2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 2022 data\n",
    "YEAR = 2022\n",
    "MAX_TICKERS = None  # Collect ALL US tickers (~12,000)\n",
    "\n",
    "data_2022, errors_2022 = collect_year_data(us_tickers, year=YEAR, max_tickers=MAX_TICKERS)\n",
    "\n",
    "if len(data_2022) > 0:\n",
    "    filename = f\"stock_data_{YEAR}.csv\"\n",
    "    data_2022.to_csv(filename, index=False)\n",
    "    print(f\"\\n\u2705 Data saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#",
    "#",
    " ",
    "S",
    "t",
    "e",
    "p",
    " ",
    "6",
    ":",
    " ",
    "C",
    "o",
    "l",
    "l",
    "e",
    "c",
    "t",
    " ",
    "D",
    "a",
    "t",
    "a",
    " ",
    "f",
    "o",
    "r",
    " ",
    "2",
    "0",
    "2",
    "1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 2021 data\n",
    "YEAR = 2021\n",
    "MAX_TICKERS = None  # Collect ALL US tickers (~12,000)\n",
    "\n",
    "data_2021, errors_2021 = collect_year_data(us_tickers, year=YEAR, max_tickers=MAX_TICKERS)\n",
    "\n",
    "if len(data_2021) > 0:\n",
    "    filename = f\"stock_data_{YEAR}.csv\"\n",
    "    data_2021.to_csv(filename, index=False)\n",
    "    print(f\"\\n\u2705 Data saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#",
    "#",
    " ",
    "S",
    "t",
    "e",
    "p",
    " ",
    "7",
    ":",
    " ",
    "C",
    "o",
    "l",
    "l",
    "e",
    "c",
    "t",
    " ",
    "D",
    "a",
    "t",
    "a",
    " ",
    "f",
    "o",
    "r",
    " ",
    "2",
    "0",
    "2",
    "0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 2020 data\n",
    "YEAR = 2020\n",
    "MAX_TICKERS = None  # Collect ALL US tickers (~12,000)\n",
    "\n",
    "data_2020, errors_2020 = collect_year_data(us_tickers, year=YEAR, max_tickers=MAX_TICKERS)\n",
    "\n",
    "if len(data_2020) > 0:\n",
    "    filename = f\"stock_data_{YEAR}.csv\"\n",
    "    data_2020.to_csv(filename, index=False)\n",
    "    print(f\"\\n\u2705 Data saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#",
    "#",
    " ",
    "S",
    "t",
    "e",
    "p",
    " ",
    "8",
    ":",
    " ",
    "C",
    "o",
    "l",
    "l",
    "e",
    "c",
    "t",
    " ",
    "D",
    "a",
    "t",
    "a",
    " ",
    "f",
    "o",
    "r",
    " ",
    "2",
    "0",
    "1",
    "9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Collect 2019 data\n",
    "YEAR = 2019\n",
    "MAX_TICKERS = None  # Collect ALL US tickers (~12,000)\n",
    "\n",
    "data_2019, errors_2019 = collect_year_data(us_tickers, year=YEAR, max_tickers=MAX_TICKERS)\n",
    "\n",
    "if len(data_2019) > 0:\n",
    "    filename = f\"stock_data_{YEAR}.csv\"\n",
    "    data_2019.to_csv(filename, index=False)\n",
    "    print(f\"\\n\u2705 Data saved to '{filename}'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis: Review Collected Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Review what we've collected\n",
    "import glob\n",
    "\n",
    "print(\"\ud83d\udcc1 Available data files:\")\n",
    "data_files = sorted(glob.glob(\"stock_data_*.csv\"))\n",
    "\n",
    "total_rows = 0\n",
    "for file in data_files:\n",
    "    df = pd.read_csv(file)\n",
    "    total_rows += len(df)\n",
    "    print(f\"  {file}: {len(df):,} rows, {df['ticker'].nunique()} tickers\")\n",
    "\n",
    "print(f\"\\n\ud83d\udcca Total: {total_rows:,} rows across {len(data_files)} files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Analyze errors\n",
    "error_files = sorted(glob.glob(\"errors_*.json\"))\n",
    "\n",
    "if error_files:\n",
    "    print(\"\ud83d\udcdd Error analysis:\")\n",
    "    \n",
    "    for error_file in error_files:\n",
    "        with open(error_file, 'r') as f:\n",
    "            errors = json.load(f)\n",
    "        \n",
    "        # Count error types\n",
    "        error_types = {}\n",
    "        for error in errors:\n",
    "            for err_msg in error.get('errors', []):\n",
    "                err_type = err_msg.split(':')[0] if ':' in err_msg else err_msg\n",
    "                error_types[err_type] = error_types.get(err_type, 0) + 1\n",
    "        \n",
    "        print(f\"\\n{error_file}: {len(errors)} failed tickers\")\n",
    "        for err_type, count in sorted(error_types.items(), key=lambda x: x[1], reverse=True)[:5]:\n",
    "            print(f\"  - {err_type}: {count}\")\n",
    "else:\n",
    "    print(\"No error files found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Optional: Combine All Years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all years into one file\n",
    "years = [2019, 2020, 2021, 2022, 2023, 2024]\n",
    "all_data = []\n",
    "\n",
    "for year in years:\n",
    "    filename = f\"stock_data_{year}.csv\"\n",
    "    if os.path.exists(filename):\n",
    "        df = pd.read_csv(filename)\n",
    "        df['quarter'] = pd.PeriodIndex(df['quarter'], freq='Q')\n",
    "        all_data.append(df)\n",
    "        print(f\"\u2713 Loaded {year}: {len(df)} rows\")\n",
    "    else:\n",
    "        print(f\"\u2717 {filename} not found\")\n",
    "\n",
    "if all_data:\n",
    "    combined = pd.concat(all_data, ignore_index=True)\n",
    "    combined = combined.sort_values(['ticker', 'quarter']).reset_index(drop=True)\n",
    "    \n",
    "    # Recalculate rankings\n",
    "    combined['mkt_cap_rank'] = combined.groupby('quarter')['mkt_cap'].rank(method='dense', ascending=False).astype(int)\n",
    "    \n",
    "    combined.to_csv(\"stock_data_combined_6years.csv\", index=False)\n",
    "    \n",
    "    print(f\"\\n\u2705 Combined dataset saved!\")\n",
    "    print(f\"   Total: {len(combined):,} rows\")\n",
    "    print(f\"   Tickers: {combined['ticker'].nunique()}\")\n",
    "    print(f\"   Period: {combined['quarter'].min()} to {combined['quarter'].max()}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}