{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ecbf6f5a",
   "metadata": {},
   "source": [
    "# Fixed Multi-Ticker Data Collection\n",
    "\n",
    "This notebook contains the fixed version of your code to pull financial data for multiple tickers.\n",
    "\n",
    "**Key fixes:**\n",
    "1. Proper error handling to prevent empty concatenation\n",
    "2. Better API response handling for different data formats\n",
    "3. Data validation and cleaning\n",
    "4. Progress tracking and summary reporting\n",
    "5. Rate limiting to avoid API issues\n",
    "\n",
    "**Target columns:** `quarter`, `ticker`, `industry`, `sector`, `debt_to_assets`, `mkt_cap`, `stock_price`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "71781212",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import time\n",
    "from typing import Optional, List, Dict, Any\n",
    "\n",
    "# Your API key\n",
    "API = \"7cNMpVzb43GKtm05iRTDWJtyJXSylX8J\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a13a3b6f",
   "metadata": {},
   "source": [
    "## Helper Functions\n",
    "\n",
    "These functions handle API calls and data processing with proper error handling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6e425e54",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_json(url: str, params: Dict[str, Any] = {}) -> Optional[List[Dict]]:\n",
    "    \"\"\"Safely get JSON data from API with error handling\"\"\"\n",
    "    try:\n",
    "        params[\"apikey\"] = API\n",
    "        response = requests.get(url, params=params, timeout=10)\n",
    "        response.raise_for_status()  # Raise an exception for bad status codes\n",
    "        js = response.json()\n",
    "        \n",
    "        # Handle different response formats\n",
    "        if isinstance(js, dict) and \"historical\" in js:\n",
    "            return js[\"historical\"]\n",
    "        elif isinstance(js, list):\n",
    "            return js\n",
    "        else:\n",
    "            print(f\"Unexpected response format: {type(js)}\")\n",
    "            return None\n",
    "    except Exception as e:\n",
    "        print(f\"Error fetching data from {url}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "05be11ff",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def process_ticker_data(ticker: str) -> Optional[pd.DataFrame]:\n",
    "    \"\"\"Process data for a single ticker and return DataFrame with required columns\"\"\"\n",
    "    print(f\"Processing {ticker}...\")\n",
    "    \n",
    "    try:\n",
    "        # Get balance sheet data\n",
    "        bs = get_json(\n",
    "            f\"https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}\", \n",
    "            {\"period\": \"quarter\", \"limit\": 20}\n",
    "        )\n",
    "        \n",
    "        # Get market cap data\n",
    "        mc = get_json(\n",
    "            f\"https://financialmodelingprep.com/api/v3/historical-market-capitalization/{ticker}\", \n",
    "            {\"limit\": 1000}\n",
    "        )\n",
    "        \n",
    "        # Get price data\n",
    "        px = get_json(\n",
    "            f\"https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}\", \n",
    "            {\"serietype\": \"line\", \"timeseries\": 1000}\n",
    "        )\n",
    "        \n",
    "        # Get company profile\n",
    "        profile = get_json(f\"https://financialmodelingprep.com/api/v3/profile/{ticker}\")\n",
    "        \n",
    "        # Check if all data is available\n",
    "        if not all([bs, mc, px, profile]):\n",
    "            print(f\"Missing data for {ticker}, skipping.\")\n",
    "            return None\n",
    "        \n",
    "        # Extract company info\n",
    "        industry = profile[0].get(\"industry\", \"Unknown\")\n",
    "        sector = profile[0].get(\"sector\", \"Unknown\")\n",
    "        \n",
    "        # Process balance sheet data\n",
    "        bs_df = (\n",
    "            pd.DataFrame(bs)\n",
    "            .loc[:, [\"date\", \"shortTermDebt\", \"longTermDebt\", \"totalAssets\"]]\n",
    "            .assign(\n",
    "                date=lambda d: pd.to_datetime(d.date),\n",
    "                quarter=lambda d: d.date.dt.to_period(\"Q\"),\n",
    "                debt_to_assets=lambda d: (\n",
    "                    (d.shortTermDebt.fillna(0) + d.longTermDebt.fillna(0)) / \n",
    "                    d.totalAssets.replace(0, pd.NA)\n",
    "                )\n",
    "            )\n",
    "            .dropna(subset=[\"debt_to_assets\"])\n",
    "        )\n",
    "        \n",
    "        # Process market cap data\n",
    "        mc_df = (\n",
    "            pd.DataFrame(mc)\n",
    "            .assign(\n",
    "                date=lambda d: pd.to_datetime(d.date),\n",
    "                quarter=lambda d: d.date.dt.to_period(\"Q\")\n",
    "            )\n",
    "            .sort_values(\"date\")\n",
    "            .drop_duplicates(\"quarter\", keep=\"last\")\n",
    "            .rename(columns={\"marketCap\": \"mkt_cap\"})\n",
    "            [[\"quarter\", \"mkt_cap\"]]\n",
    "        )\n",
    "        \n",
    "        # Process price data\n",
    "        px_df = (\n",
    "            pd.DataFrame(px)\n",
    "            .assign(\n",
    "                date=lambda d: pd.to_datetime(d.date),\n",
    "                quarter=lambda d: d.date.dt.to_period(\"Q\")\n",
    "            )\n",
    "            .sort_values(\"date\")\n",
    "            .drop_duplicates(\"quarter\", keep=\"last\")\n",
    "            .rename(columns={\"close\": \"stock_price\"})\n",
    "            [[\"quarter\", \"stock_price\"]]\n",
    "        )\n",
    "        \n",
    "        # Merge all data\n",
    "        merged = (\n",
    "            bs_df.merge(mc_df, on=\"quarter\", how=\"left\")\n",
    "                 .merge(px_df, on=\"quarter\", how=\"left\")\n",
    "                 .assign(ticker=ticker, industry=industry, sector=sector)\n",
    "                 [[\"quarter\", \"ticker\", \"industry\", \"sector\", \"debt_to_assets\", \"mkt_cap\", \"stock_price\"]]\n",
    "                 .dropna()  # Remove rows with missing data\n",
    "        )\n",
    "        \n",
    "        if len(merged) == 0:\n",
    "            print(f\"No valid data after merging for {ticker}\")\n",
    "            return None\n",
    "            \n",
    "        return merged\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"Error processing {ticker}: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a92754b",
   "metadata": {
    "lines_to_next_cell": 1
   },
   "outputs": [],
   "source": [
    "def get_ticker_data(tickers: List[str], max_tickers: int = 50) -> pd.DataFrame:\n",
    "    \"\"\"Get data for multiple tickers with proper error handling\"\"\"\n",
    "    all_data = []\n",
    "    successful_tickers = []\n",
    "    failed_tickers = []\n",
    "    \n",
    "    for i, ticker in enumerate(tickers[:max_tickers]):\n",
    "        print(f\"\\nProgress: {i+1}/{min(len(tickers), max_tickers)}\")\n",
    "        \n",
    "        ticker_data = process_ticker_data(ticker)\n",
    "        \n",
    "        if ticker_data is not None and len(ticker_data) > 0:\n",
    "            all_data.append(ticker_data)\n",
    "            successful_tickers.append(ticker)\n",
    "            print(f\"✓ Successfully processed {ticker} - {len(ticker_data)} quarters\")\n",
    "        else:\n",
    "            failed_tickers.append(ticker)\n",
    "            print(f\"✗ Failed to process {ticker}\")\n",
    "        \n",
    "        # Rate limiting\n",
    "        time.sleep(0.5)\n",
    "    \n",
    "    print(f\"\\n=== SUMMARY ===\")\n",
    "    print(f\"Successful: {len(successful_tickers)} tickers\")\n",
    "    print(f\"Failed: {len(failed_tickers)} tickers\")\n",
    "    \n",
    "    if len(all_data) == 0:\n",
    "        print(\"No data collected. Returning empty DataFrame.\")\n",
    "        return pd.DataFrame(columns=[\"quarter\", \"ticker\", \"industry\", \"sector\", \"debt_to_assets\", \"mkt_cap\", \"stock_price\"])\n",
    "    \n",
    "    # Combine all data\n",
    "    final_df = pd.concat(all_data, ignore_index=True)\n",
    "    final_df = final_df.sort_values([\"ticker\", \"quarter\"]).reset_index(drop=True)\n",
    "    \n",
    "    print(f\"Final dataset: {len(final_df)} rows, {final_df['ticker'].nunique()} unique tickers\")\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "760799f3",
   "metadata": {},
   "source": [
    "## Step 1: Get List of US Tickers\n",
    "\n",
    "Fetch all available US tickers and filter them to remove penny stocks and complex symbols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c51cdb0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fetching ticker list...\n",
      "Found 12283 US tickers\n",
      "Sample tickers: ['STXD', 'DXYZ', 'ACVA', 'STXG', 'PWRD', 'TPZ', 'THIR', 'NVR', 'SMR', 'BRK-A']\n"
     ]
    }
   ],
   "source": [
    "# Get list of US tickers\n",
    "print(\"Fetching ticker list...\")\n",
    "tickers_data = get_json(\"https://financialmodelingprep.com/api/v3/stock/list\")\n",
    "\n",
    "if tickers_data:\n",
    "    # Filter for US exchanges and remove penny stocks\n",
    "    us_tickers = [\n",
    "        d[\"symbol\"] for d in tickers_data \n",
    "        if d[\"exchangeShortName\"] in [\"NYSE\", \"NASDAQ\"] \n",
    "        and (d.get(\"price\") is not None and d.get(\"price\", 0) > 5)  # Filter out penny stocks and None prices\n",
    "        and len(d[\"symbol\"]) <= 5  # Filter out complex symbols\n",
    "        and \".\" not in d[\"symbol\"]  # Filter out preferred shares\n",
    "    ]\n",
    "    \n",
    "    print(f\"Found {len(us_tickers)} US tickers\")\n",
    "    print(f\"Sample tickers: {us_tickers[:10]}\")\n",
    "else:\n",
    "    print(\"Failed to fetch ticker list. Using sample tickers.\")\n",
    "    us_tickers = [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"JPM\", \"JNJ\", \"V\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "178fa35c",
   "metadata": {},
   "source": [
    "## Step 2: Test with Single Ticker\n",
    "\n",
    "Before processing multiple tickers, let's test with AAPL to ensure everything works correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "48293608",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing with a single ticker (AAPL)...\n",
      "Processing AAPL...\n",
      "\n",
      "Test successful! Sample data:\n",
      "  quarter ticker              industry      sector  debt_to_assets  \\\n",
      "0  2025Q1   AAPL  Consumer Electronics  Technology        0.296426   \n",
      "1  2024Q4   AAPL  Consumer Electronics  Technology        0.281323   \n",
      "2  2024Q3   AAPL  Consumer Electronics  Technology        0.326207   \n",
      "3  2024Q2   AAPL  Consumer Electronics  Technology        0.305490   \n",
      "4  2024Q1   AAPL  Consumer Electronics  Technology        0.309978   \n",
      "\n",
      "        mkt_cap  stock_price  \n",
      "0  3.330635e+12       222.13  \n",
      "1  3.754818e+12       250.42  \n",
      "2  3.514042e+12       233.00  \n",
      "3  3.219858e+12       210.62  \n",
      "4  2.641796e+12       171.48  \n",
      "\n",
      "Data types:\n",
      "quarter           period[Q-DEC]\n",
      "ticker                   object\n",
      "industry                 object\n",
      "sector                   object\n",
      "debt_to_assets          float64\n",
      "mkt_cap                 float64\n",
      "stock_price             float64\n",
      "dtype: object\n",
      "\n",
      "Shape: (16, 7)\n"
     ]
    }
   ],
   "source": [
    "# Test with a single ticker first\n",
    "print(\"Testing with a single ticker (AAPL)...\")\n",
    "test_data = process_ticker_data(\"AAPL\")\n",
    "\n",
    "if test_data is not None:\n",
    "    print(\"\\nTest successful! Sample data:\")\n",
    "    print(test_data.head())\n",
    "    print(f\"\\nData types:\")\n",
    "    print(test_data.dtypes)\n",
    "    print(f\"\\nShape: {test_data.shape}\")\n",
    "else:\n",
    "    print(\"Test failed. Please check your API key.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "166974ec",
   "metadata": {},
   "source": [
    "## Step 3: Collect Data for Multiple Tickers\n",
    "\n",
    "Now let's process multiple tickers. You can adjust `max_tickers` to control how many tickers to process.\n",
    "\n",
    "**Note:** Start with a small number (20-50) for testing, then increase as needed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b6e6e97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting data collection for 20 tickers...\n",
      "\n",
      "Progress: 1/20\n",
      "Processing STXD...\n",
      "Missing data for STXD, skipping.\n",
      "✗ Failed to process STXD\n",
      "\n",
      "Progress: 2/20\n",
      "Processing DXYZ...\n",
      "✓ Successfully processed DXYZ - 2 quarters\n",
      "\n",
      "Progress: 3/20\n",
      "Processing ACVA...\n",
      "✓ Successfully processed ACVA - 16 quarters\n",
      "\n",
      "Progress: 4/20\n",
      "Processing STXG...\n",
      "Missing data for STXG, skipping.\n",
      "✗ Failed to process STXG\n",
      "\n",
      "Progress: 5/20\n",
      "Processing PWRD...\n",
      "Missing data for PWRD, skipping.\n",
      "✗ Failed to process PWRD\n",
      "\n",
      "Progress: 6/20\n",
      "Processing TPZ...\n",
      "✓ Successfully processed TPZ - 7 quarters\n",
      "\n",
      "Progress: 7/20\n",
      "Processing THIR...\n",
      "Missing data for THIR, skipping.\n",
      "✗ Failed to process THIR\n",
      "\n",
      "Progress: 8/20\n",
      "Processing NVR...\n",
      "✓ Successfully processed NVR - 16 quarters\n",
      "\n",
      "Progress: 9/20\n",
      "Processing SMR...\n",
      "✓ Successfully processed SMR - 16 quarters\n",
      "\n",
      "Progress: 10/20\n",
      "Processing BRK-A...\n",
      "✓ Successfully processed BRK-A - 16 quarters\n",
      "\n",
      "Progress: 11/20\n",
      "Processing NMAX...\n",
      "Missing data for NMAX, skipping.\n",
      "✗ Failed to process NMAX\n",
      "\n",
      "Progress: 12/20\n",
      "Processing HPE...\n",
      "✓ Successfully processed HPE - 16 quarters\n",
      "\n",
      "Progress: 13/20\n",
      "Processing CVX...\n",
      "✓ Successfully processed CVX - 16 quarters\n",
      "\n",
      "Progress: 14/20\n",
      "Processing EXP...\n",
      "✓ Successfully processed EXP - 15 quarters\n",
      "\n",
      "Progress: 15/20\n",
      "Processing T...\n",
      "✓ Successfully processed T - 16 quarters\n",
      "\n",
      "Progress: 16/20\n",
      "Processing XOM...\n",
      "✓ Successfully processed XOM - 16 quarters\n",
      "\n",
      "Progress: 17/20\n",
      "Processing DIS...\n",
      "✓ Successfully processed DIS - 17 quarters\n",
      "\n",
      "Progress: 18/20\n",
      "Processing QBTS...\n",
      "✓ Successfully processed QBTS - 16 quarters\n",
      "\n",
      "Progress: 19/20\n",
      "Processing HMY...\n",
      "✓ Successfully processed HMY - 15 quarters\n",
      "\n",
      "Progress: 20/20\n",
      "Processing GFI...\n",
      "✓ Successfully processed GFI - 8 quarters\n",
      "\n",
      "=== SUMMARY ===\n",
      "Successful: 15 tickers\n",
      "Failed: 5 tickers\n",
      "Final dataset: 208 rows, 15 unique tickers\n",
      "\n",
      "Data collection complete!\n"
     ]
    }
   ],
   "source": [
    "# Process the tickers (adjust max_tickers as needed)\n",
    "MAX_TICKERS = 20  # Start with 20 for testing\n",
    "\n",
    "print(f\"Starting data collection for {MAX_TICKERS} tickers...\")\n",
    "final_dataset = get_ticker_data(us_tickers, max_tickers=MAX_TICKERS)\n",
    "\n",
    "print(f\"\\nData collection complete!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "084e6284",
   "metadata": {},
   "source": [
    "## Step 4: Display Results and Save Data\n",
    "\n",
    "Let's examine the collected data and save it to a CSV file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7940c6a7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== SAMPLE DATA ===\n",
      "  quarter ticker            industry             sector debt_to_assets  \\\n",
      "0  2021Q2   ACVA  Auto - Dealerships  Consumer Cyclical       0.003023   \n",
      "1  2021Q3   ACVA  Auto - Dealerships  Consumer Cyclical       0.002881   \n",
      "2  2021Q4   ACVA  Auto - Dealerships  Consumer Cyclical       0.003922   \n",
      "3  2022Q1   ACVA  Auto - Dealerships  Consumer Cyclical       0.063755   \n",
      "4  2022Q2   ACVA  Auto - Dealerships  Consumer Cyclical       0.079275   \n",
      "5  2022Q3   ACVA  Auto - Dealerships  Consumer Cyclical       0.085442   \n",
      "6  2022Q4   ACVA  Auto - Dealerships  Consumer Cyclical       0.083799   \n",
      "7  2023Q1   ACVA  Auto - Dealerships  Consumer Cyclical       0.095966   \n",
      "8  2023Q2   ACVA  Auto - Dealerships  Consumer Cyclical        0.11213   \n",
      "9  2023Q3   ACVA  Auto - Dealerships  Consumer Cyclical       0.109479   \n",
      "\n",
      "        mkt_cap  stock_price  \n",
      "0  3.973622e+09        25.63  \n",
      "1  2.786754e+09        17.89  \n",
      "2  2.941018e+09        18.84  \n",
      "3  2.320782e+09        14.81  \n",
      "4  1.028508e+09         6.54  \n",
      "5  1.139300e+09         7.19  \n",
      "6  1.300926e+09         8.21  \n",
      "7  2.058678e+09        12.91  \n",
      "8  2.770591e+09        17.27  \n",
      "9  2.435297e+09        15.18  \n",
      "\n",
      "=== DATA SUMMARY ===\n",
      "Total rows: 208\n",
      "Unique tickers: 15\n",
      "Date range: 2021Q2 to 2025Q1\n",
      "Industries: 12\n",
      "Sectors: 7\n",
      "\n",
      "=== COLUMN STATISTICS ===\n",
      "            mkt_cap    stock_price\n",
      "count  2.080000e+02     208.000000\n",
      "mean   1.443338e+11   41715.557510\n",
      "std    2.291432e+11  146393.325293\n",
      "min    7.756419e+07       0.664100\n",
      "25%    2.543656e+09      11.907500\n",
      "50%    1.843772e+10      21.260000\n",
      "75%    2.022322e+11     147.742500\n",
      "max    1.148337e+12  798441.600000\n",
      "\n",
      "✅ Data saved to 'stock_data_notebook.csv'\n"
     ]
    }
   ],
   "source": [
    "# Display results\n",
    "if len(final_dataset) > 0:\n",
    "    print(\"=== SAMPLE DATA ===\")\n",
    "    print(final_dataset.head(10))\n",
    "    \n",
    "    print(\"\\n=== DATA SUMMARY ===\")\n",
    "    print(f\"Total rows: {len(final_dataset):,}\")\n",
    "    print(f\"Unique tickers: {final_dataset['ticker'].nunique()}\")\n",
    "    print(f\"Date range: {final_dataset['quarter'].min()} to {final_dataset['quarter'].max()}\")\n",
    "    print(f\"Industries: {final_dataset['industry'].nunique()}\")\n",
    "    print(f\"Sectors: {final_dataset['sector'].nunique()}\")\n",
    "    \n",
    "    print(\"\\n=== COLUMN STATISTICS ===\")\n",
    "    print(final_dataset.describe())\n",
    "    \n",
    "    # Save to CSV\n",
    "    filename = \"stock_data_notebook.csv\"\n",
    "    final_dataset.to_csv(filename, index=False)\n",
    "    print(f\"\\n✅ Data saved to '{filename}'\")\n",
    "    \n",
    "else:\n",
    "    print(\"❌ No data was collected. Please check your API key and network connection.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4659a7a5",
   "metadata": {},
   "source": [
    "## Step 5: Basic Data Analysis (Optional)\n",
    "\n",
    "Let's do some quick analysis of the collected data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b139b6fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== INDUSTRY BREAKDOWN ===\n",
      "industry\n",
      "Oil & Gas Integrated           32\n",
      "Gold                           23\n",
      "Entertainment                  17\n",
      "Auto - Dealerships             16\n",
      "Insurance - Diversified        16\n",
      "Communication Equipment        16\n",
      "Residential Construction       16\n",
      "Computer Hardware              16\n",
      "Renewable Utilities            16\n",
      "Telecommunications Services    16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== SECTOR BREAKDOWN ===\n",
      "sector\n",
      "Basic Materials           38\n",
      "Communication Services    33\n",
      "Consumer Cyclical         32\n",
      "Energy                    32\n",
      "Technology                32\n",
      "Financial Services        25\n",
      "Utilities                 16\n",
      "Name: count, dtype: int64\n",
      "\n",
      "=== DEBT-TO-ASSETS STATISTICS ===\n",
      "Mean: 0.2285\n",
      "Median: 0.1639\n",
      "Min: 0.0000\n",
      "Max: 1.5692\n",
      "\n",
      "=== MARKET CAP RANGES ===\n",
      "Mean Market Cap: $144.33B\n",
      "Median Market Cap: $18.44B\n",
      "Largest Market Cap: $1148.34B\n",
      "Smallest Market Cap: $0.08B\n"
     ]
    }
   ],
   "source": [
    "if len(final_dataset) > 0:\n",
    "    print(\"=== INDUSTRY BREAKDOWN ===\")\n",
    "    industry_counts = final_dataset['industry'].value_counts()\n",
    "    print(industry_counts.head(10))\n",
    "    \n",
    "    print(\"\\n=== SECTOR BREAKDOWN ===\")\n",
    "    sector_counts = final_dataset['sector'].value_counts()\n",
    "    print(sector_counts)\n",
    "    \n",
    "    print(\"\\n=== DEBT-TO-ASSETS STATISTICS ===\")\n",
    "    print(f\"Mean: {final_dataset['debt_to_assets'].mean():.4f}\")\n",
    "    print(f\"Median: {final_dataset['debt_to_assets'].median():.4f}\")\n",
    "    print(f\"Min: {final_dataset['debt_to_assets'].min():.4f}\")\n",
    "    print(f\"Max: {final_dataset['debt_to_assets'].max():.4f}\")\n",
    "    \n",
    "    print(\"\\n=== MARKET CAP RANGES ===\")\n",
    "    final_dataset['mkt_cap_billions'] = final_dataset['mkt_cap'] / 1e9\n",
    "    print(f\"Mean Market Cap: ${final_dataset['mkt_cap_billions'].mean():.2f}B\")\n",
    "    print(f\"Median Market Cap: ${final_dataset['mkt_cap_billions'].median():.2f}B\")\n",
    "    print(f\"Largest Market Cap: ${final_dataset['mkt_cap_billions'].max():.2f}B\")\n",
    "    print(f\"Smallest Market Cap: ${final_dataset['mkt_cap_billions'].min():.2f}B\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b916e7df",
   "metadata": {},
   "source": [
    "## Step 6: Scale Up (Optional)\n",
    "\n",
    "If you want to collect data for more tickers, you can run this cell with a larger number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "abe7ad03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scale-up cell ready. Uncomment the code above to run with more tickers.\n"
     ]
    }
   ],
   "source": [
    "# Uncomment and run this cell to collect data for more tickers\n",
    "# WARNING: This will take longer and use more API calls\n",
    "\n",
    "# LARGE_BATCH = 100  # Adjust as needed\n",
    "# print(f\"Collecting data for {LARGE_BATCH} tickers...\")\n",
    "# large_dataset = get_ticker_data(us_tickers, max_tickers=LARGE_BATCH)\n",
    "\n",
    "# if len(large_dataset) > 0:\n",
    "#     large_dataset.to_csv(\"large_stock_data.csv\", index=False)\n",
    "#     print(f\"Large dataset saved: {len(large_dataset)} rows, {large_dataset['ticker'].nunique()} tickers\")\n",
    "\n",
    "print(\"Scale-up cell ready. Uncomment the code above to run with more tickers.\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b402471",
   "metadata": {
    "vscode": {
     "languageId": "sql"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
