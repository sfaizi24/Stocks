{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "# Separated Stock Price and Financial Statement Data Collection\n",
        "\n",
        "This notebook collects financial data for **US stocks with market cap > $1B** and separates:\n",
        "1. **Stock price data** - Aligned to calendar quarter ends (March 31, June 30, Sept 30, Dec 31)\n",
        "2. **Financial statement data** - Aligned to company fiscal quarters with calendar date mapping\n",
        "\n",
        "**Key features:**\n",
        "1. **Market cap filter**: Only collects data for stocks with market cap > $1B\n",
        "2. **Rate limiting**: 750 API calls per minute\n",
        "3. **Year-by-year collection**: Each year saved to separate files\n",
        "4. **Fiscal/Calendar alignment**: Properly handles different fiscal year ends\n",
        "5. **Enhanced metadata**: Includes company name, ETF/Fund flags\n",
        "6. **Error tracking**: Detailed logs for debugging\n",
        "\n",
        "**Output files per year:**\n",
        "- `stock_prices_YYYY.csv`: ticker, company_name, quarter_end_date, stock_price, market_cap, mkt_cap_rank, industry, sector, isETF, isFund\n",
        "- `financial_statements_YYYY.csv`: ticker, company_name, fiscal_quarter, calendar_date, debt_to_assets, book_to_market, earnings_yield, industry, sector\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Setup and Configuration\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import requests\n",
        "import pandas as pd\n",
        "import time\n",
        "from typing import Optional, List, Dict, Any, Tuple\n",
        "from datetime import datetime, timedelta\n",
        "import json\n",
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import numpy as np\n",
        "\n",
        "load_dotenv(\".env\")\n",
        "API = os.getenv(\"API\")  \n",
        "\n",
        "# Rate limiting configuration\n",
        "API_CALLS_PER_MINUTE = 750\n",
        "SECONDS_PER_CALL = 60 / API_CALLS_PER_MINUTE  # 0.08 seconds per call\n",
        "\n",
        "# Session and timer for rate limiting\n",
        "session = requests.Session()\n",
        "LAST_API_CALL = 0.0\n",
        "\n",
        "# Market cap threshold (1 billion)\n",
        "MARKET_CAP_THRESHOLD = 1e9\n",
        "\n",
        "print(f\"Rate limit configured: {API_CALLS_PER_MINUTE} calls/minute ({SECONDS_PER_CALL:.2f} seconds/call)\")\n",
        "print(f\"Market cap filter: > ${MARKET_CAP_THRESHOLD/1e9:.0f}B\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Helper Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_json(url: str, params: Dict[str, Any] = {}) -> Optional[Any]:\n",
        "    \"\"\"Safely get JSON data from API with error handling and rate limit retry\"\"\"\n",
        "    global LAST_API_CALL, session\n",
        "    try:\n",
        "        params['apikey'] = API\n",
        "        elapsed = time.time() - LAST_API_CALL\n",
        "        if elapsed < SECONDS_PER_CALL:\n",
        "            time.sleep(SECONDS_PER_CALL - elapsed)\n",
        "        response = session.get(url, params=params, timeout=10)\n",
        "        LAST_API_CALL = time.time()\n",
        "        if response.status_code == 429:\n",
        "            print('‚ö†Ô∏è  Rate limit hit! Waiting 30 seconds...')\n",
        "            time.sleep(30)\n",
        "            return get_json(url, params)\n",
        "        response.raise_for_status()\n",
        "        js = response.json()\n",
        "        if isinstance(js, dict) and 'historical' in js:\n",
        "            return js['historical']\n",
        "        elif isinstance(js, list):\n",
        "            return js\n",
        "        else:\n",
        "            return js\n",
        "    except requests.exceptions.HTTPError as e:\n",
        "        print(f'HTTP Error {e.response.status_code}: {e}')\n",
        "        return None\n",
        "    except Exception as e:\n",
        "        print(f'Error fetching data: {e}')\n",
        "        return None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_quarter_end_dates(year: int) -> List[datetime]:\n",
        "    \"\"\"Get calendar quarter end dates for a given year\"\"\"\n",
        "    return [\n",
        "        datetime(year, 3, 31),   # Q1\n",
        "        datetime(year, 6, 30),   # Q2\n",
        "        datetime(year, 9, 30),   # Q3\n",
        "        datetime(year, 12, 31)   # Q4\n",
        "    ]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def check_market_cap(ticker: str, year: int, precomputed: Optional[float] = None) -> Tuple[bool, Optional[float]]:\n",
        "    \"\"\"Check if ticker had market cap above threshold in given year\"\"\"\n",
        "    if precomputed is not None:\n",
        "        return precomputed > MARKET_CAP_THRESHOLD, precomputed\n",
        "    try:\n",
        "        start_date = f'{year}-01-01'\n",
        "        end_date = f'{year}-12-31'\n",
        "        mc_data = get_json(\n",
        "            f'https://financialmodelingprep.com/api/v3/historical-market-capitalization/{ticker}',\n",
        "            {'from': start_date, 'to': end_date}\n",
        "        )\n",
        "        if not mc_data:\n",
        "            return False, None\n",
        "        mc_df = pd.DataFrame(mc_data)\n",
        "        avg_market_cap = mc_df['marketCap'].mean()\n",
        "        return avg_market_cap > MARKET_CAP_THRESHOLD, avg_market_cap\n",
        "    except Exception as e:\n",
        "        print(f'Error checking market cap for {ticker}: {e}')\n",
        "        return False, None\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_bulk_profiles(tickers: List[str]) -> Dict[str, Any]:\n",
        "    \"\"\"Fetch company profiles in bulk.\"\"\"\n",
        "    data = get_json(f'https://financialmodelingprep.com/api/v3/profile/{','.join(tickers)}')\n",
        "    profiles = {}\n",
        "    if isinstance(data, list):\n",
        "        for item in data:\n",
        "            symbol = item.get('symbol')\n",
        "            profiles[symbol] = item\n",
        "    return profiles\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def get_historical_tickers(year: int) -> List[str]:\n",
        "    \"\"\"Get list of US tickers that existed in a specific year\"\"\"\n",
        "    print(f\"Fetching ticker list for year {year}...\")\n",
        "    \n",
        "    # Try to get historical ticker list from end of previous year\n",
        "    date = f\"{year-1}-12-31\"\n",
        "    \n",
        "    # First try to get available stocks for that date\n",
        "    available_stocks = get_json(\n",
        "        f\"https://financialmodelingprep.com/api/v3/available-traded/list\",\n",
        "        {\"date\": date}\n",
        "    )\n",
        "    \n",
        "    if available_stocks:\n",
        "        # Filter for US exchanges\n",
        "        us_tickers = [\n",
        "            stock[\"symbol\"] for stock in available_stocks \n",
        "            if stock.get(\"exchangeShortName\") in [\"NYSE\", \"NASDAQ\", \"AMEX\"]\n",
        "            and len(stock[\"symbol\"]) <= 5\n",
        "            and \".\" not in stock[\"symbol\"]\n",
        "        ]\n",
        "        print(f\"‚úÖ Found {len(us_tickers)} US tickers for {year}\")\n",
        "        return us_tickers\n",
        "    \n",
        "    # Fallback: use current ticker list with a warning\n",
        "    print(f\"‚ö†Ô∏è  Could not get historical ticker list for {year}, using current list\")\n",
        "    tickers_data = get_json(\"https://financialmodelingprep.com/api/v3/stock/list\")\n",
        "    \n",
        "    if tickers_data:\n",
        "        # Filter for US exchanges and remove penny stocks\n",
        "        us_tickers = [\n",
        "            d[\"symbol\"] for d in tickers_data \n",
        "            if d[\"exchangeShortName\"] in [\"NYSE\", \"NASDAQ\"] \n",
        "            and (d.get(\"price\") is not None and d.get(\"price\", 0) > 5)\n",
        "            and len(d[\"symbol\"]) <= 5\n",
        "            and \".\" not in d[\"symbol\"]\n",
        "        ]\n",
        "        \n",
        "        print(f\"‚úÖ Found {len(us_tickers)} current US tickers\")\n",
        "        return us_tickers\n",
        "    else:\n",
        "        print(\"‚ùå Failed to fetch ticker list. Using sample tickers.\")\n",
        "        return [\"AAPL\", \"MSFT\", \"GOOGL\", \"AMZN\", \"TSLA\", \"META\", \"NVDA\", \"JPM\", \"JNJ\", \"V\"]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Stock Price Collection Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_stock_prices_for_ticker(ticker: str, year: int, profile_data: Optional[Dict[str, Any]] = None) -> Tuple[Optional[pd.DataFrame], Dict[str, Any], int]:\n",
        "    \"\"\"Collect stock price data aligned to calendar quarter ends\"\"\"\n",
        "    error_log = {'ticker': ticker, 'year': year, 'errors': []}\n",
        "    api_calls = 0\n",
        "    \n",
        "    try:\n",
        "        # Check market cap\n",
        "        is_large_cap, avg_market_cap = check_market_cap(ticker, year)\n",
        "        api_calls += 1\n",
        "        \n",
        "        if not is_large_cap:\n",
        "            error_log['errors'].append(f'Market cap below threshold (avg: ${avg_market_cap:,.0f})')\n",
        "            return None, error_log, api_calls\n",
        "        \n",
        "        # Get profile data if not provided\n",
        "        if profile_data is None:\n",
        "            profile = get_json(f'https://financialmodelingprep.com/api/v3/profile/{ticker}')\n",
        "            api_calls += 1\n",
        "            profile_data = profile[0] if profile and len(profile) > 0 else {}\n",
        "        \n",
        "        # Extract profile information\n",
        "        company_name = profile_data.get('companyName', 'Unknown')\n",
        "        industry = profile_data.get('industry', 'Unknown')\n",
        "        sector = profile_data.get('sector', 'Unknown')\n",
        "        is_etf = profile_data.get('isEtf', False)\n",
        "        is_fund = profile_data.get('isFund', False)\n",
        "        \n",
        "        # Get historical prices for the year\n",
        "        start_date = f'{year}-01-01'\n",
        "        end_date = f'{year}-12-31'\n",
        "        \n",
        "        px_data = get_json(\n",
        "            f'https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}',\n",
        "            {'from': start_date, 'to': end_date}\n",
        "        )\n",
        "        api_calls += 1\n",
        "        \n",
        "        mc_data = get_json(\n",
        "            f'https://financialmodelingprep.com/api/v3/historical-market-capitalization/{ticker}',\n",
        "            {'from': start_date, 'to': end_date}\n",
        "        )\n",
        "        api_calls += 1\n",
        "        \n",
        "        if not px_data or not mc_data:\n",
        "            error_log['errors'].append('Missing price or market cap data')\n",
        "            return None, error_log, api_calls\n",
        "        \n",
        "        # Convert to DataFrames\n",
        "        px_df = pd.DataFrame(px_data)\n",
        "        px_df['date'] = pd.to_datetime(px_df['date'])\n",
        "        \n",
        "        mc_df = pd.DataFrame(mc_data)\n",
        "        mc_df['date'] = pd.to_datetime(mc_df['date'])\n",
        "        \n",
        "        # Get quarter end dates\n",
        "        quarter_ends = get_quarter_end_dates(year)\n",
        "        \n",
        "        # Collect data for each quarter end\n",
        "        quarter_data = []\n",
        "        for q_idx, q_end in enumerate(quarter_ends, 1):\n",
        "            # Find closest trading day to quarter end (within 7 days)\n",
        "            date_range = pd.date_range(q_end - timedelta(days=7), q_end)\n",
        "            \n",
        "            # Get price data\n",
        "            px_match = px_df[px_df['date'].isin(date_range)].sort_values('date', ascending=False)\n",
        "            if len(px_match) == 0:\n",
        "                continue\n",
        "                \n",
        "            px_row = px_match.iloc[0]\n",
        "            \n",
        "            # Get market cap data\n",
        "            mc_match = mc_df[mc_df['date'].isin(date_range)].sort_values('date', ascending=False)\n",
        "            if len(mc_match) == 0:\n",
        "                continue\n",
        "                \n",
        "            mc_row = mc_match.iloc[0]\n",
        "            \n",
        "            quarter_data.append({\n",
        "                'ticker': ticker,\n",
        "                'company_name': company_name,\n",
        "                'quarter_end_date': q_end.strftime('%Y-%m-%d'),\n",
        "                'actual_date': px_row['date'].strftime('%Y-%m-%d'),\n",
        "                'stock_price': px_row['adjClose'],\n",
        "                'market_cap': mc_row['marketCap'],\n",
        "                'industry': industry,\n",
        "                'sector': sector,\n",
        "                'isETF': is_etf,\n",
        "                'isFund': is_fund,\n",
        "                'quarter': f'{year}Q{q_idx}'\n",
        "            })\n",
        "        \n",
        "        if not quarter_data:\n",
        "            error_log['errors'].append('No valid quarter-end data found')\n",
        "            return None, error_log, api_calls\n",
        "            \n",
        "        return pd.DataFrame(quarter_data), error_log, api_calls\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_log['errors'].append(f'Exception: {str(e)}')\n",
        "        return None, error_log, api_calls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Financial Statement Collection Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_financial_statements_for_ticker(ticker: str, year: int, profile_data: Optional[Dict[str, Any]] = None) -> Tuple[Optional[pd.DataFrame], Dict[str, Any], int]:\n",
        "    \"\"\"Collect financial statement data aligned to fiscal quarters\"\"\"\n",
        "    error_log = {'ticker': ticker, 'year': year, 'errors': []}\n",
        "    api_calls = 0\n",
        "    \n",
        "    try:\n",
        "        # Check market cap\n",
        "        is_large_cap, avg_market_cap = check_market_cap(ticker, year)\n",
        "        api_calls += 1\n",
        "        \n",
        "        if not is_large_cap:\n",
        "            error_log['errors'].append(f'Market cap below threshold (avg: ${avg_market_cap:,.0f})')\n",
        "            return None, error_log, api_calls\n",
        "        \n",
        "        # Get profile data if not provided\n",
        "        if profile_data is None:\n",
        "            profile = get_json(f'https://financialmodelingprep.com/api/v3/profile/{ticker}')\n",
        "            api_calls += 1\n",
        "            profile_data = profile[0] if profile and len(profile) > 0 else {}\n",
        "        \n",
        "        # Extract profile information\n",
        "        company_name = profile_data.get('companyName', 'Unknown')\n",
        "        industry = profile_data.get('industry', 'Unknown')\n",
        "        sector = profile_data.get('sector', 'Unknown')\n",
        "        \n",
        "        # Get financial statements\n",
        "        bs = get_json(\n",
        "            f'https://financialmodelingprep.com/api/v3/balance-sheet-statement/{ticker}',\n",
        "            {'period': 'quarter', 'limit': 20}\n",
        "        )\n",
        "        api_calls += 1\n",
        "        \n",
        "        inc = get_json(\n",
        "            f'https://financialmodelingprep.com/api/v3/income-statement/{ticker}',\n",
        "            {'period': 'quarter', 'limit': 20}\n",
        "        )\n",
        "        api_calls += 1\n",
        "        \n",
        "        if not bs or not inc:\n",
        "            error_log['errors'].append('Missing financial statement data')\n",
        "            return None, error_log, api_calls\n",
        "        \n",
        "        # Convert to DataFrames and filter for year\n",
        "        bs_df = pd.DataFrame(bs)\n",
        "        bs_df['date'] = pd.to_datetime(bs_df['date'])\n",
        "        bs_df = bs_df[bs_df['date'].dt.year == year]\n",
        "        \n",
        "        inc_df = pd.DataFrame(inc)\n",
        "        inc_df['date'] = pd.to_datetime(inc_df['date'])\n",
        "        inc_df = inc_df[inc_df['date'].dt.year == year]\n",
        "        \n",
        "        if len(bs_df) == 0 or len(inc_df) == 0:\n",
        "            error_log['errors'].append(f'No financial data for year {year}')\n",
        "            return None, error_log, api_calls\n",
        "        \n",
        "        # Get stock prices for book-to-market and earnings yield calculations\n",
        "        start_date = f'{year}-01-01'\n",
        "        end_date = f'{year}-12-31'\n",
        "        px_data = get_json(\n",
        "            f'https://financialmodelingprep.com/api/v3/historical-price-full/{ticker}',\n",
        "            {'from': start_date, 'to': end_date}\n",
        "        )\n",
        "        api_calls += 1\n",
        "        \n",
        "        if not px_data:\n",
        "            error_log['errors'].append('Missing price data for ratios')\n",
        "            return None, error_log, api_calls\n",
        "            \n",
        "        px_df = pd.DataFrame(px_data)\n",
        "        px_df['date'] = pd.to_datetime(px_df['date'])\n",
        "        \n",
        "        # Process each fiscal quarter\n",
        "        statement_data = []\n",
        "        \n",
        "        for idx, bs_row in bs_df.iterrows():\n",
        "            # Find matching income statement\n",
        "            inc_match = inc_df[inc_df['date'] == bs_row['date']]\n",
        "            if len(inc_match) == 0:\n",
        "                continue\n",
        "                \n",
        "            inc_row = inc_match.iloc[0]\n",
        "            \n",
        "            # Calculate debt to assets\n",
        "            total_debt = (bs_row.get('shortTermDebt', 0) or 0) + (bs_row.get('longTermDebt', 0) or 0)\n",
        "            total_assets = bs_row.get('totalAssets', 0)\n",
        "            debt_to_assets = total_debt / total_assets if total_assets > 0 else None\n",
        "            \n",
        "            # Get stock price near statement date for ratios\n",
        "            statement_date = bs_row['date']\n",
        "            date_range = pd.date_range(statement_date - timedelta(days=7), statement_date + timedelta(days=7))\n",
        "            px_match = px_df[px_df['date'].isin(date_range)].sort_values('date')\n",
        "            \n",
        "            if len(px_match) > 0:\n",
        "                stock_price = px_match.iloc[len(px_match)//2]['adjClose']  # Use middle date\n",
        "                \n",
        "                # Calculate book to market\n",
        "                book_value = bs_row.get('totalStockholdersEquity', 0)\n",
        "                shares = inc_row.get('weightedAverageShsOut', 0)\n",
        "                book_per_share = book_value / shares if shares > 0 else None\n",
        "                book_to_market = book_per_share / stock_price if book_per_share and stock_price > 0 else None\n",
        "                \n",
        "                # Calculate earnings yield\n",
        "                eps = inc_row.get('eps', 0)\n",
        "                earnings_yield = eps / stock_price if stock_price > 0 else None\n",
        "            else:\n",
        "                book_to_market = None\n",
        "                earnings_yield = None\n",
        "            \n",
        "            # Determine fiscal quarter\n",
        "            fiscal_period = bs_row.get('period', '')\n",
        "            fiscal_year = bs_row.get('calendarYear', year)\n",
        "            \n",
        "            statement_data.append({\n",
        "                'ticker': ticker,\n",
        "                'company_name': company_name,\n",
        "                'fiscal_quarter': f'{fiscal_year}-{fiscal_period}',\n",
        "                'calendar_date': statement_date.strftime('%Y-%m-%d'),\n",
        "                'debt_to_assets': debt_to_assets,\n",
        "                'book_to_market': book_to_market,\n",
        "                'earnings_yield': earnings_yield,\n",
        "                'industry': industry,\n",
        "                'sector': sector,\n",
        "                'total_assets': total_assets,\n",
        "                'total_debt': total_debt,\n",
        "                'book_value': book_value,\n",
        "                'eps': eps,\n",
        "                'shares_outstanding': shares\n",
        "            })\n",
        "        \n",
        "        if not statement_data:\n",
        "            error_log['errors'].append('No valid statement data found')\n",
        "            return None, error_log, api_calls\n",
        "            \n",
        "        df = pd.DataFrame(statement_data)\n",
        "        # Keep only required columns for output\n",
        "        output_cols = ['ticker', 'company_name', 'fiscal_quarter', 'calendar_date', \n",
        "                      'debt_to_assets', 'book_to_market', 'earnings_yield', 'industry', 'sector']\n",
        "        return df[output_cols], error_log, api_calls\n",
        "        \n",
        "    except Exception as e:\n",
        "        error_log['errors'].append(f'Exception: {str(e)}')\n",
        "        return None, error_log, api_calls\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "vscode": {
          "languageId": "raw"
        }
      },
      "source": [
        "## Main Collection Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "def collect_year_data_separated(tickers: List[str], year: int, max_tickers: Optional[int] = None, \n",
        "                               save_progress: bool = True, progress_interval: int = 100, \n",
        "                               batch_size: int = 50) -> Tuple[pd.DataFrame, pd.DataFrame, List[Dict]]:\n",
        "    \"\"\"Collect both stock price and financial statement data for a year\"\"\"\n",
        "    # Initialize collections\n",
        "    all_price_data = []\n",
        "    all_statement_data = []\n",
        "    all_errors = []\n",
        "    \n",
        "    successful_tickers = []\n",
        "    failed_tickers = []\n",
        "    skipped_tickers = []\n",
        "    total_api_calls = 0\n",
        "    \n",
        "    tickers_to_process = tickers[:max_tickers] if max_tickers else tickers\n",
        "    total_tickers = len(tickers_to_process)\n",
        "    \n",
        "    print(f\"\\n{'='*70}\")\n",
        "    print(f\"  COLLECTING SEPARATED DATA FOR YEAR {year}\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total tickers to check: {total_tickers}\")\n",
        "    print(f\"Market cap filter: >${MARKET_CAP_THRESHOLD/1e9:.0f}B\")\n",
        "    print(f\"API rate limit: {API_CALLS_PER_MINUTE} calls/minute\")\n",
        "    print(f\"Batch size: {batch_size} tickers\")\n",
        "    print(f\"Progress saves: Every {progress_interval} tickers\")\n",
        "    print(f\"{'='*70}\\n\")\n",
        "    \n",
        "    start_time = time.time()\n",
        "    \n",
        "    # Process tickers in batches\n",
        "    for batch_start in range(0, total_tickers, batch_size):\n",
        "        batch_end = min(batch_start + batch_size, total_tickers)\n",
        "        batch_tickers = tickers_to_process[batch_start:batch_end]\n",
        "        \n",
        "        # Progress update\n",
        "        if batch_start > 0:\n",
        "            elapsed = time.time() - start_time\n",
        "            avg_time = elapsed / batch_start\n",
        "            remaining = (total_tickers - batch_start) * avg_time\n",
        "            \n",
        "            print(f\"\\n[Progress: {batch_start}/{total_tickers} ({batch_start/total_tickers*100:.1f}%)]\")\n",
        "            print(f\"  Time: {elapsed/60:.1f}min elapsed, ~{remaining/60:.1f}min remaining\")\n",
        "            print(f\"  Success: {len(successful_tickers)}, Failed: {len(failed_tickers)}, Skipped (small cap): {len(skipped_tickers)}\")\n",
        "            print(f\"  API calls: {total_api_calls} ({total_api_calls/elapsed*60:.0f}/minute avg)\")\n",
        "        \n",
        "        print(f\"\\n  Processing batch {batch_start//batch_size + 1}: tickers {batch_start+1}-{batch_end}\")\n",
        "        \n",
        "        # Get bulk profiles for the batch\n",
        "        profiles = get_bulk_profiles(batch_tickers)\n",
        "        total_api_calls += 1\n",
        "        \n",
        "        # Process each ticker in the batch\n",
        "        for ticker in batch_tickers:\n",
        "            profile_data = profiles.get(ticker)\n",
        "            \n",
        "            # Collect stock price data\n",
        "            price_data, price_error, price_calls = collect_stock_prices_for_ticker(ticker, year, profile_data)\n",
        "            total_api_calls += price_calls\n",
        "            \n",
        "            # Collect financial statement data\n",
        "            statement_data, statement_error, statement_calls = collect_financial_statements_for_ticker(ticker, year, profile_data)\n",
        "            total_api_calls += statement_calls\n",
        "            \n",
        "            # Determine success/failure\n",
        "            has_price_data = price_data is not None and len(price_data) > 0\n",
        "            has_statement_data = statement_data is not None and len(statement_data) > 0\n",
        "            \n",
        "            if has_price_data or has_statement_data:\n",
        "                successful_tickers.append(ticker)\n",
        "                if has_price_data:\n",
        "                    all_price_data.append(price_data)\n",
        "                if has_statement_data:\n",
        "                    all_statement_data.append(statement_data)\n",
        "                print(\"‚úì\", end=\"\", flush=True)\n",
        "            elif any(\"Market cap below threshold\" in err for err in price_error.get(\"errors\", [])):\n",
        "                skipped_tickers.append(ticker)\n",
        "                print(\"‚óã\", end=\"\", flush=True)\n",
        "            else:\n",
        "                failed_tickers.append(ticker)\n",
        "                # Combine errors from both collections\n",
        "                combined_errors = {\n",
        "                    'ticker': ticker,\n",
        "                    'year': year,\n",
        "                    'price_errors': price_error.get('errors', []),\n",
        "                    'statement_errors': statement_error.get('errors', [])\n",
        "                }\n",
        "                all_errors.append(combined_errors)\n",
        "                print(\"‚úó\", end=\"\", flush=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "        # Save progress periodically\n",
        "        if save_progress and (batch_end % progress_interval == 0 or batch_end == total_tickers):\n",
        "            if all_price_data:\n",
        "                temp_price_df = pd.concat(all_price_data, ignore_index=True)\n",
        "                temp_price_df['mkt_cap_rank'] = temp_price_df.groupby('quarter')['market_cap'].rank(method='dense', ascending=False).astype(int)\n",
        "                price_filename = f\"progress_prices_{year}_tickers_{batch_end}.csv\"\n",
        "                temp_price_df.to_csv(price_filename, index=False)\n",
        "                print(f\"\\n  üíæ Price data saved: {price_filename} ({len(temp_price_df)} rows)\")\n",
        "            \n",
        "            if all_statement_data:\n",
        "                temp_statement_df = pd.concat(all_statement_data, ignore_index=True)\n",
        "                statement_filename = f\"progress_statements_{year}_tickers_{batch_end}.csv\"\n",
        "                temp_statement_df.to_csv(statement_filename, index=False)\n",
        "                print(f\"  üíæ Statement data saved: {statement_filename} ({len(temp_statement_df)} rows)\")\n",
        "    \n",
        "    # Final summary\n",
        "    total_time = time.time() - start_time\n",
        "    \n",
        "    print(f\"\\n\\n{'='*70}\")\n",
        "    print(f\"  YEAR {year} COLLECTION COMPLETE\")\n",
        "    print(f\"{'='*70}\")\n",
        "    print(f\"Total time: {total_time/60:.1f} minutes ({total_time/3600:.2f} hours)\")\n",
        "    print(f\"Successful: {len(successful_tickers)} tickers\")\n",
        "    print(f\"Failed: {len(failed_tickers)} tickers\")\n",
        "    print(f\"Skipped (small cap): {len(skipped_tickers)} tickers\")\n",
        "    print(f\"Total API calls: {total_api_calls:,} ({total_api_calls/total_time*60:.0f}/minute avg)\")\n",
        "    \n",
        "    # Prepare final DataFrames\n",
        "    if all_price_data:\n",
        "        final_price_df = pd.concat(all_price_data, ignore_index=True)\n",
        "        final_price_df = final_price_df.drop_duplicates(['ticker', 'quarter_end_date'], keep='last')\n",
        "        final_price_df['mkt_cap_rank'] = final_price_df.groupby('quarter')['market_cap'].rank(method='dense', ascending=False).astype(int)\n",
        "        final_price_df = final_price_df.sort_values(['ticker', 'quarter_end_date']).reset_index(drop=True)\n",
        "        # Drop the quarter column used for ranking\n",
        "        final_price_df = final_price_df.drop('quarter', axis=1)\n",
        "    else:\n",
        "        final_price_df = pd.DataFrame()\n",
        "    \n",
        "    if all_statement_data:\n",
        "        final_statement_df = pd.concat(all_statement_data, ignore_index=True)\n",
        "        final_statement_df = final_statement_df.drop_duplicates(['ticker', 'fiscal_quarter', 'calendar_date'], keep='last')\n",
        "        final_statement_df = final_statement_df.sort_values(['ticker', 'calendar_date']).reset_index(drop=True)\n",
        "    else:\n",
        "        final_statement_df = pd.DataFrame()\n",
        "    \n",
        "    print(f\"\\nüìä Final datasets:\")\n",
        "    print(f\"   Stock prices: {len(final_price_df)} rows, {final_price_df['ticker'].nunique() if len(final_price_df) > 0 else 0} tickers\")\n",
        "    print(f\"   Financial statements: {len(final_statement_df)} rows, {final_statement_df['ticker'].nunique() if len(final_statement_df) > 0 else 0} tickers\")\n",
        "    \n",
        "    # Save error log\n",
        "    if all_errors:\n",
        "        error_filename = f\"errors_separated_{year}.json\"\n",
        "        with open(error_filename, 'w') as f:\n",
        "            json.dump(all_errors, f, indent=2, default=str)\n",
        "        print(f\"\\nüìù Error log saved: {error_filename} ({len(all_errors)} errors)\")\n",
        "    \n",
        "    # Clean up progress files\n",
        "    if save_progress:\n",
        "        for progress_file in [f for f in os.listdir('.') if f.startswith(f'progress_') and str(year) in f]:\n",
        "            os.remove(progress_file)\n",
        "        print(f\"üßπ Cleaned up progress files\")\n",
        "    \n",
        "    return final_price_df, final_statement_df, all_errors\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.13.3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
